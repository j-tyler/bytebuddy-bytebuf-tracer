# ByteBuf Flow Tracker - Performance Benchmarks

**Generated:** 2025-11-15
**JVM:** OpenJDK 64-Bit Server VM, 21.0.8
**Platform:** Linux 4.4.0

---

## Purpose

This document establishes performance baselines for the ByteBuf Flow Tracker agent. **The agent is a development/debugging tool**, not intended for production use. The overhead is expected and acceptable for leak detection during development.

---

## Key Findings

### Throughput Impact

| Benchmark Scenario | Without Agent | With Agent | Overhead Factor |
|-------------------|---------------|------------|-----------------|
| Simple allocate/release | 23M ops/s | 894 ops/s | **25,700x** |
| Method chain (3 hops) | 22M ops/s | 901 ops/s | **24,800x** |
| Random walk (5-50 hops) | 2.5M ops/s | 906 ops/s | **2,750x** |

### Memory Impact

| Metric | Without Agent | With Agent | Change |
|--------|--------------|------------|--------|
| **GC Allocation Rate** | ~7,000 MB/s | ~0.65 MB/s | **-99.99%** |
| **Per-Op Allocation** | 320 B/op | 760 B/op | **+137%** |
| **GC Collections** | 166 | 0 | **-100%** |

---

## Why the Overhead Exists

The agent intercepts **every ByteBuf method call** (release, retain, etc.) to build a trie of execution paths. Each interception:
1. **Trie traversal** - ConcurrentHashMap lookups to find/create nodes
2. **Path recording** - Stores full call stack for each allocation
3. **Weak reference tracking** - Registers each ByteBuf with GC to detect leaks
4. **String interning** - Deduplicates method signatures on first use

Deep method chains amplify this overhead linearly.

---

## Memory Optimization Design

### Bit-Packed Statistics
**WHY:** Reduces trie node memory footprint to allow tracking larger applications.

Each trie node packs two counters into a single `AtomicLong`:
- **40 bits** for traversals (max: 1.1 trillion)
- **24 bits** for leaks (max: 16.7 million)
- **Layout:** `[63-40: leakCount][39-0: traversalCount]`

**Savings:** 16 bytes per node = 16 MB per million nodes

**Trade-off:** Zero impact on throughput (overhead dominated by HashMap lookups), but 50% smaller trie memory footprint.

### Zero-Allocation Hot Path
**WHY:** Avoid lambda capture overhead in statistics updates.

Uses manual CAS loops instead of `AtomicLong.updateAndGet()`:
```java
long current, newValue;
do {
    current = packedCounts.get();
    long traversals = current & TRAVERSAL_MASK;
    if (traversals >= TRAVERSAL_MAX) return; // Saturation
    newValue = ((current >>> LEAK_SHIFT) << LEAK_SHIFT) | (traversals + 1);
} while (!packedCounts.compareAndSet(current, newValue));
```

**Savings:** Eliminates lambda allocation on hot path (statistics are updated millions of times).

---

## Benchmark Suites

### 1. ByteBufFlowBenchmark (4 tests)
Basic ByteBuf allocation and method tracking overhead.
- Simple allocate/release
- Pass to method
- Method chain (3 hops)
- Tight loop (100 iterations)

### 2. DirectMemoryFilteringBenchmark (5 tests)
Mixed heap/direct buffer workloads (80% heap, 20% direct).
- Ambiguous buffer allocations
- Critical direct buffer operations
- High frequency heap allocations
- Method chain overhead
- Realistic mixed workload

### 3. RandomWalkBenchmark (1 test)
Deep call chains with random branching (5-50 hops through 50 methods).
**Best represents real-world application behavior.**

---

## Recommendations

### Development Use
1. **Use on focused test suites** - Not full integration tests
2. **Filter with `include` patterns** - Reduce instrumentation scope
3. **Increase heap size** - `-Xmx4g` or higher for trie growth
4. **Use `trackDirectOnly=true`** - If only direct buffer leaks matter (~50% overhead reduction)

### Future Optimization Targets
Based on profiling, the highest-impact optimizations would be:
1. **Sampling mode** - Track 1-in-N operations (NÃ— overhead reduction)
2. **Async trie updates** - Buffer operations, flush periodically
3. **Path compression** - Merge linear trie paths to reduce node count
4. **Off-heap trie** - Move trie to native memory to reduce GC pressure

---

## Reproducing Benchmarks

```bash
cd bytebuf-flow-benchmarks

# Build benchmarks
mvn clean install -DskipTests

# Run WITHOUT agent (baseline)
export JMH_GC_PROF=true
java -jar target/benchmarks.jar -prof gc -rf json -rff baseline_results.json

# Run WITH agent (overhead)
export JMH_GC_PROF=true
java "-javaagent:../bytebuf-flow-tracker/target/bytebuf-flow-tracker-1.0.0-SNAPSHOT-agent.jar=include=com.example.bytebuf.benchmarks" \
  -jar target/benchmarks.jar -prof gc -rf json -rff agent_results.json
```

**Note:** The `JMH_GC_PROF` environment variable is required to pass benchmark validation. GC profiling is mandatory for meaningful allocation rate measurements.

---

## Conclusion

The ByteBuf Flow Tracker provides comprehensive leak detection at the cost of severe performance degradation (99.96-99.99% slower). This tradeoff is acceptable for its intended use case: **debugging memory leaks during development**.

The bit-packed statistics optimization reduces memory footprint by 50%, allowing the tool to track larger applications without running out of heap. Future work should focus on reducing throughput overhead through sampling or async processing.
